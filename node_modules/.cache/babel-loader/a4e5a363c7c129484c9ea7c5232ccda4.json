{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.parse = void 0;\nvar tslib_1 = require(\"tslib\");\nvar assert_1 = tslib_1.__importDefault(require(\"assert\"));\nvar types = tslib_1.__importStar(require(\"ast-types\"));\nvar b = types.builders;\nvar isObject = types.builtInTypes.object;\nvar isArray = types.builtInTypes.array;\nvar options_1 = require(\"./options\");\nvar lines_1 = require(\"./lines\");\nvar comments_1 = require(\"./comments\");\nvar util = tslib_1.__importStar(require(\"./util\"));\nfunction parse(source, options) {\n  options = options_1.normalize(options);\n  var lines = lines_1.fromString(source, options);\n  var sourceWithoutTabs = lines.toString({\n    tabWidth: options.tabWidth,\n    reuseWhitespace: false,\n    useTabs: false\n  });\n  var comments = [];\n  var ast = options.parser.parse(sourceWithoutTabs, {\n    jsx: true,\n    loc: true,\n    locations: true,\n    range: options.range,\n    comment: true,\n    onComment: comments,\n    tolerant: util.getOption(options, \"tolerant\", true),\n    ecmaVersion: 6,\n    sourceType: util.getOption(options, \"sourceType\", \"module\")\n  });\n  // Use ast.tokens if possible, and otherwise fall back to the Esprima\n  // tokenizer. All the preconfigured ../parsers/* expose ast.tokens\n  // automatically, but custom parsers might need additional configuration\n  // to avoid this fallback.\n  var tokens = Array.isArray(ast.tokens) ? ast.tokens : require(\"esprima\").tokenize(sourceWithoutTabs, {\n    loc: true\n  });\n  // We will reattach the tokens array to the file object below.\n  delete ast.tokens;\n  // Make sure every token has a token.value string.\n  tokens.forEach(function (token) {\n    if (typeof token.value !== \"string\") {\n      token.value = lines.sliceString(token.loc.start, token.loc.end);\n    }\n  });\n  if (Array.isArray(ast.comments)) {\n    comments = ast.comments;\n    delete ast.comments;\n  }\n  if (ast.loc) {\n    // If the source was empty, some parsers give loc.{start,end}.line\n    // values of 0, instead of the minimum of 1.\n    util.fixFaultyLocations(ast, lines);\n  } else {\n    ast.loc = {\n      start: lines.firstPos(),\n      end: lines.lastPos()\n    };\n  }\n  ast.loc.lines = lines;\n  ast.loc.indent = 0;\n  var file;\n  var program;\n  if (ast.type === \"Program\") {\n    program = ast;\n    // In order to ensure we reprint leading and trailing program\n    // comments, wrap the original Program node with a File node. Only\n    // ESTree parsers (Acorn and Esprima) return a Program as the root AST\n    // node. Most other (Babylon-like) parsers return a File.\n    file = b.file(ast, options.sourceFileName || null);\n    file.loc = {\n      start: lines.firstPos(),\n      end: lines.lastPos(),\n      lines: lines,\n      indent: 0\n    };\n  } else if (ast.type === \"File\") {\n    file = ast;\n    program = file.program;\n  }\n  // Expose file.tokens unless the caller passed false for options.tokens.\n  if (options.tokens) {\n    file.tokens = tokens;\n  }\n  // Expand the Program's .loc to include all comments (not just those\n  // attached to the Program node, as its children may have comments as\n  // well), since sometimes program.loc.{start,end} will coincide with the\n  // .loc.{start,end} of the first and last *statements*, mistakenly\n  // excluding comments that fall outside that region.\n  var trueProgramLoc = util.getTrueLoc({\n    type: program.type,\n    loc: program.loc,\n    body: [],\n    comments: comments\n  }, lines);\n  program.loc.start = trueProgramLoc.start;\n  program.loc.end = trueProgramLoc.end;\n  // Passing file.program here instead of just file means that initial\n  // comments will be attached to program.body[0] instead of program.\n  comments_1.attach(comments, program.body.length ? file.program : file, lines);\n  // Return a copy of the original AST so that any changes made may be\n  // compared to the original.\n  return new TreeCopier(lines, tokens).copy(file);\n}\nexports.parse = parse;\nvar TreeCopier = function TreeCopier(lines, tokens) {\n  assert_1.default.ok(this instanceof TreeCopier);\n  this.lines = lines;\n  this.tokens = tokens;\n  this.startTokenIndex = 0;\n  this.endTokenIndex = tokens.length;\n  this.indent = 0;\n  this.seen = new Map();\n};\nvar TCp = TreeCopier.prototype;\nTCp.copy = function (node) {\n  if (this.seen.has(node)) {\n    return this.seen.get(node);\n  }\n  if (isArray.check(node)) {\n    var copy_1 = new Array(node.length);\n    this.seen.set(node, copy_1);\n    node.forEach(function (item, i) {\n      copy_1[i] = this.copy(item);\n    }, this);\n    return copy_1;\n  }\n  if (!isObject.check(node)) {\n    return node;\n  }\n  util.fixFaultyLocations(node, this.lines);\n  var copy = Object.create(Object.getPrototypeOf(node), {\n    original: {\n      // Provide a link from the copy to the original.\n      value: node,\n      configurable: false,\n      enumerable: false,\n      writable: true\n    }\n  });\n  this.seen.set(node, copy);\n  var loc = node.loc;\n  var oldIndent = this.indent;\n  var newIndent = oldIndent;\n  var oldStartTokenIndex = this.startTokenIndex;\n  var oldEndTokenIndex = this.endTokenIndex;\n  if (loc) {\n    // When node is a comment, we set node.loc.indent to\n    // node.loc.start.column so that, when/if we print the comment by\n    // itself, we can strip that much whitespace from the left margin of\n    // the comment. This only really matters for multiline Block comments,\n    // but it doesn't hurt for Line comments.\n    if (node.type === \"Block\" || node.type === \"Line\" || node.type === \"CommentBlock\" || node.type === \"CommentLine\" || this.lines.isPrecededOnlyByWhitespace(loc.start)) {\n      newIndent = this.indent = loc.start.column;\n    }\n    // Every node.loc has a reference to the original source lines as well\n    // as a complete list of source tokens.\n    loc.lines = this.lines;\n    loc.tokens = this.tokens;\n    loc.indent = newIndent;\n    // Set loc.start.token and loc.end.token such that\n    // loc.tokens.slice(loc.start.token, loc.end.token) returns a list of\n    // all the tokens that make up this node.\n    this.findTokenRange(loc);\n  }\n  var keys = Object.keys(node);\n  var keyCount = keys.length;\n  for (var i = 0; i < keyCount; ++i) {\n    var key = keys[i];\n    if (key === \"loc\") {\n      copy[key] = node[key];\n    } else if (key === \"tokens\" && node.type === \"File\") {\n      // Preserve file.tokens (uncopied) in case client code cares about\n      // it, even though Recast ignores it when reprinting.\n      copy[key] = node[key];\n    } else {\n      copy[key] = this.copy(node[key]);\n    }\n  }\n  this.indent = oldIndent;\n  this.startTokenIndex = oldStartTokenIndex;\n  this.endTokenIndex = oldEndTokenIndex;\n  return copy;\n};\n// If we didn't have any idea where in loc.tokens to look for tokens\n// contained by this loc, a binary search would be appropriate, but\n// because we maintain this.startTokenIndex and this.endTokenIndex as we\n// traverse the AST, we only need to make small (linear) adjustments to\n// those indexes with each recursive iteration.\nTCp.findTokenRange = function (loc) {\n  // In the unlikely event that loc.tokens[this.startTokenIndex] starts\n  // *after* loc.start, we need to rewind this.startTokenIndex first.\n  while (this.startTokenIndex > 0) {\n    var token = loc.tokens[this.startTokenIndex];\n    if (util.comparePos(loc.start, token.loc.start) < 0) {\n      --this.startTokenIndex;\n    } else break;\n  }\n  // In the unlikely event that loc.tokens[this.endTokenIndex - 1] ends\n  // *before* loc.end, we need to fast-forward this.endTokenIndex first.\n  while (this.endTokenIndex < loc.tokens.length) {\n    var token = loc.tokens[this.endTokenIndex];\n    if (util.comparePos(token.loc.end, loc.end) < 0) {\n      ++this.endTokenIndex;\n    } else break;\n  }\n  // Increment this.startTokenIndex until we've found the first token\n  // contained by this node.\n  while (this.startTokenIndex < this.endTokenIndex) {\n    var token = loc.tokens[this.startTokenIndex];\n    if (util.comparePos(token.loc.start, loc.start) < 0) {\n      ++this.startTokenIndex;\n    } else break;\n  }\n  // Index into loc.tokens of the first token within this node.\n  loc.start.token = this.startTokenIndex;\n  // Decrement this.endTokenIndex until we've found the first token after\n  // this node (not contained by the node).\n  while (this.endTokenIndex > this.startTokenIndex) {\n    var token = loc.tokens[this.endTokenIndex - 1];\n    if (util.comparePos(loc.end, token.loc.end) < 0) {\n      --this.endTokenIndex;\n    } else break;\n  }\n  // Index into loc.tokens of the first token *after* this node.\n  // If loc.start.token === loc.end.token, the node contains no tokens,\n  // and the index is that of the next token following this node.\n  loc.end.token = this.endTokenIndex;\n};","map":{"version":3,"names":["Object","defineProperty","exports","value","parse","tslib_1","require","assert_1","__importDefault","types","__importStar","b","builders","isObject","builtInTypes","object","isArray","array","options_1","lines_1","comments_1","util","source","options","normalize","lines","fromString","sourceWithoutTabs","toString","tabWidth","reuseWhitespace","useTabs","comments","ast","parser","jsx","loc","locations","range","comment","onComment","tolerant","getOption","ecmaVersion","sourceType","tokens","Array","tokenize","forEach","token","sliceString","start","end","fixFaultyLocations","firstPos","lastPos","indent","file","program","type","sourceFileName","trueProgramLoc","getTrueLoc","body","attach","length","TreeCopier","copy","default","ok","startTokenIndex","endTokenIndex","seen","Map","TCp","prototype","node","has","get","check","copy_1","set","item","i","create","getPrototypeOf","original","configurable","enumerable","writable","oldIndent","newIndent","oldStartTokenIndex","oldEndTokenIndex","isPrecededOnlyByWhitespace","column","findTokenRange","keys","keyCount","key","comparePos"],"sources":["C:/Users/Acer/Desktop/dev__book/dev__book/node_modules/jscodeshift/node_modules/recast/lib/parser.js"],"sourcesContent":["\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.parse = void 0;\nvar tslib_1 = require(\"tslib\");\nvar assert_1 = tslib_1.__importDefault(require(\"assert\"));\nvar types = tslib_1.__importStar(require(\"ast-types\"));\nvar b = types.builders;\nvar isObject = types.builtInTypes.object;\nvar isArray = types.builtInTypes.array;\nvar options_1 = require(\"./options\");\nvar lines_1 = require(\"./lines\");\nvar comments_1 = require(\"./comments\");\nvar util = tslib_1.__importStar(require(\"./util\"));\nfunction parse(source, options) {\n    options = options_1.normalize(options);\n    var lines = lines_1.fromString(source, options);\n    var sourceWithoutTabs = lines.toString({\n        tabWidth: options.tabWidth,\n        reuseWhitespace: false,\n        useTabs: false,\n    });\n    var comments = [];\n    var ast = options.parser.parse(sourceWithoutTabs, {\n        jsx: true,\n        loc: true,\n        locations: true,\n        range: options.range,\n        comment: true,\n        onComment: comments,\n        tolerant: util.getOption(options, \"tolerant\", true),\n        ecmaVersion: 6,\n        sourceType: util.getOption(options, \"sourceType\", \"module\"),\n    });\n    // Use ast.tokens if possible, and otherwise fall back to the Esprima\n    // tokenizer. All the preconfigured ../parsers/* expose ast.tokens\n    // automatically, but custom parsers might need additional configuration\n    // to avoid this fallback.\n    var tokens = Array.isArray(ast.tokens)\n        ? ast.tokens\n        : require(\"esprima\").tokenize(sourceWithoutTabs, {\n            loc: true,\n        });\n    // We will reattach the tokens array to the file object below.\n    delete ast.tokens;\n    // Make sure every token has a token.value string.\n    tokens.forEach(function (token) {\n        if (typeof token.value !== \"string\") {\n            token.value = lines.sliceString(token.loc.start, token.loc.end);\n        }\n    });\n    if (Array.isArray(ast.comments)) {\n        comments = ast.comments;\n        delete ast.comments;\n    }\n    if (ast.loc) {\n        // If the source was empty, some parsers give loc.{start,end}.line\n        // values of 0, instead of the minimum of 1.\n        util.fixFaultyLocations(ast, lines);\n    }\n    else {\n        ast.loc = {\n            start: lines.firstPos(),\n            end: lines.lastPos(),\n        };\n    }\n    ast.loc.lines = lines;\n    ast.loc.indent = 0;\n    var file;\n    var program;\n    if (ast.type === \"Program\") {\n        program = ast;\n        // In order to ensure we reprint leading and trailing program\n        // comments, wrap the original Program node with a File node. Only\n        // ESTree parsers (Acorn and Esprima) return a Program as the root AST\n        // node. Most other (Babylon-like) parsers return a File.\n        file = b.file(ast, options.sourceFileName || null);\n        file.loc = {\n            start: lines.firstPos(),\n            end: lines.lastPos(),\n            lines: lines,\n            indent: 0,\n        };\n    }\n    else if (ast.type === \"File\") {\n        file = ast;\n        program = file.program;\n    }\n    // Expose file.tokens unless the caller passed false for options.tokens.\n    if (options.tokens) {\n        file.tokens = tokens;\n    }\n    // Expand the Program's .loc to include all comments (not just those\n    // attached to the Program node, as its children may have comments as\n    // well), since sometimes program.loc.{start,end} will coincide with the\n    // .loc.{start,end} of the first and last *statements*, mistakenly\n    // excluding comments that fall outside that region.\n    var trueProgramLoc = util.getTrueLoc({\n        type: program.type,\n        loc: program.loc,\n        body: [],\n        comments: comments,\n    }, lines);\n    program.loc.start = trueProgramLoc.start;\n    program.loc.end = trueProgramLoc.end;\n    // Passing file.program here instead of just file means that initial\n    // comments will be attached to program.body[0] instead of program.\n    comments_1.attach(comments, program.body.length ? file.program : file, lines);\n    // Return a copy of the original AST so that any changes made may be\n    // compared to the original.\n    return new TreeCopier(lines, tokens).copy(file);\n}\nexports.parse = parse;\nvar TreeCopier = function TreeCopier(lines, tokens) {\n    assert_1.default.ok(this instanceof TreeCopier);\n    this.lines = lines;\n    this.tokens = tokens;\n    this.startTokenIndex = 0;\n    this.endTokenIndex = tokens.length;\n    this.indent = 0;\n    this.seen = new Map();\n};\nvar TCp = TreeCopier.prototype;\nTCp.copy = function (node) {\n    if (this.seen.has(node)) {\n        return this.seen.get(node);\n    }\n    if (isArray.check(node)) {\n        var copy_1 = new Array(node.length);\n        this.seen.set(node, copy_1);\n        node.forEach(function (item, i) {\n            copy_1[i] = this.copy(item);\n        }, this);\n        return copy_1;\n    }\n    if (!isObject.check(node)) {\n        return node;\n    }\n    util.fixFaultyLocations(node, this.lines);\n    var copy = Object.create(Object.getPrototypeOf(node), {\n        original: {\n            // Provide a link from the copy to the original.\n            value: node,\n            configurable: false,\n            enumerable: false,\n            writable: true,\n        },\n    });\n    this.seen.set(node, copy);\n    var loc = node.loc;\n    var oldIndent = this.indent;\n    var newIndent = oldIndent;\n    var oldStartTokenIndex = this.startTokenIndex;\n    var oldEndTokenIndex = this.endTokenIndex;\n    if (loc) {\n        // When node is a comment, we set node.loc.indent to\n        // node.loc.start.column so that, when/if we print the comment by\n        // itself, we can strip that much whitespace from the left margin of\n        // the comment. This only really matters for multiline Block comments,\n        // but it doesn't hurt for Line comments.\n        if (node.type === \"Block\" ||\n            node.type === \"Line\" ||\n            node.type === \"CommentBlock\" ||\n            node.type === \"CommentLine\" ||\n            this.lines.isPrecededOnlyByWhitespace(loc.start)) {\n            newIndent = this.indent = loc.start.column;\n        }\n        // Every node.loc has a reference to the original source lines as well\n        // as a complete list of source tokens.\n        loc.lines = this.lines;\n        loc.tokens = this.tokens;\n        loc.indent = newIndent;\n        // Set loc.start.token and loc.end.token such that\n        // loc.tokens.slice(loc.start.token, loc.end.token) returns a list of\n        // all the tokens that make up this node.\n        this.findTokenRange(loc);\n    }\n    var keys = Object.keys(node);\n    var keyCount = keys.length;\n    for (var i = 0; i < keyCount; ++i) {\n        var key = keys[i];\n        if (key === \"loc\") {\n            copy[key] = node[key];\n        }\n        else if (key === \"tokens\" && node.type === \"File\") {\n            // Preserve file.tokens (uncopied) in case client code cares about\n            // it, even though Recast ignores it when reprinting.\n            copy[key] = node[key];\n        }\n        else {\n            copy[key] = this.copy(node[key]);\n        }\n    }\n    this.indent = oldIndent;\n    this.startTokenIndex = oldStartTokenIndex;\n    this.endTokenIndex = oldEndTokenIndex;\n    return copy;\n};\n// If we didn't have any idea where in loc.tokens to look for tokens\n// contained by this loc, a binary search would be appropriate, but\n// because we maintain this.startTokenIndex and this.endTokenIndex as we\n// traverse the AST, we only need to make small (linear) adjustments to\n// those indexes with each recursive iteration.\nTCp.findTokenRange = function (loc) {\n    // In the unlikely event that loc.tokens[this.startTokenIndex] starts\n    // *after* loc.start, we need to rewind this.startTokenIndex first.\n    while (this.startTokenIndex > 0) {\n        var token = loc.tokens[this.startTokenIndex];\n        if (util.comparePos(loc.start, token.loc.start) < 0) {\n            --this.startTokenIndex;\n        }\n        else\n            break;\n    }\n    // In the unlikely event that loc.tokens[this.endTokenIndex - 1] ends\n    // *before* loc.end, we need to fast-forward this.endTokenIndex first.\n    while (this.endTokenIndex < loc.tokens.length) {\n        var token = loc.tokens[this.endTokenIndex];\n        if (util.comparePos(token.loc.end, loc.end) < 0) {\n            ++this.endTokenIndex;\n        }\n        else\n            break;\n    }\n    // Increment this.startTokenIndex until we've found the first token\n    // contained by this node.\n    while (this.startTokenIndex < this.endTokenIndex) {\n        var token = loc.tokens[this.startTokenIndex];\n        if (util.comparePos(token.loc.start, loc.start) < 0) {\n            ++this.startTokenIndex;\n        }\n        else\n            break;\n    }\n    // Index into loc.tokens of the first token within this node.\n    loc.start.token = this.startTokenIndex;\n    // Decrement this.endTokenIndex until we've found the first token after\n    // this node (not contained by the node).\n    while (this.endTokenIndex > this.startTokenIndex) {\n        var token = loc.tokens[this.endTokenIndex - 1];\n        if (util.comparePos(loc.end, token.loc.end) < 0) {\n            --this.endTokenIndex;\n        }\n        else\n            break;\n    }\n    // Index into loc.tokens of the first token *after* this node.\n    // If loc.start.token === loc.end.token, the node contains no tokens,\n    // and the index is that of the next token following this node.\n    loc.end.token = this.endTokenIndex;\n};\n"],"mappings":"AAAA,YAAY;;AACZA,MAAM,CAACC,cAAc,CAACC,OAAO,EAAE,YAAY,EAAE;EAAEC,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DD,OAAO,CAACE,KAAK,GAAG,KAAK,CAAC;AACtB,IAAIC,OAAO,GAAGC,OAAO,CAAC,OAAO,CAAC;AAC9B,IAAIC,QAAQ,GAAGF,OAAO,CAACG,eAAe,CAACF,OAAO,CAAC,QAAQ,CAAC,CAAC;AACzD,IAAIG,KAAK,GAAGJ,OAAO,CAACK,YAAY,CAACJ,OAAO,CAAC,WAAW,CAAC,CAAC;AACtD,IAAIK,CAAC,GAAGF,KAAK,CAACG,QAAQ;AACtB,IAAIC,QAAQ,GAAGJ,KAAK,CAACK,YAAY,CAACC,MAAM;AACxC,IAAIC,OAAO,GAAGP,KAAK,CAACK,YAAY,CAACG,KAAK;AACtC,IAAIC,SAAS,GAAGZ,OAAO,CAAC,WAAW,CAAC;AACpC,IAAIa,OAAO,GAAGb,OAAO,CAAC,SAAS,CAAC;AAChC,IAAIc,UAAU,GAAGd,OAAO,CAAC,YAAY,CAAC;AACtC,IAAIe,IAAI,GAAGhB,OAAO,CAACK,YAAY,CAACJ,OAAO,CAAC,QAAQ,CAAC,CAAC;AAClD,SAASF,KAAKA,CAACkB,MAAM,EAAEC,OAAO,EAAE;EAC5BA,OAAO,GAAGL,SAAS,CAACM,SAAS,CAACD,OAAO,CAAC;EACtC,IAAIE,KAAK,GAAGN,OAAO,CAACO,UAAU,CAACJ,MAAM,EAAEC,OAAO,CAAC;EAC/C,IAAII,iBAAiB,GAAGF,KAAK,CAACG,QAAQ,CAAC;IACnCC,QAAQ,EAAEN,OAAO,CAACM,QAAQ;IAC1BC,eAAe,EAAE,KAAK;IACtBC,OAAO,EAAE;EACb,CAAC,CAAC;EACF,IAAIC,QAAQ,GAAG,EAAE;EACjB,IAAIC,GAAG,GAAGV,OAAO,CAACW,MAAM,CAAC9B,KAAK,CAACuB,iBAAiB,EAAE;IAC9CQ,GAAG,EAAE,IAAI;IACTC,GAAG,EAAE,IAAI;IACTC,SAAS,EAAE,IAAI;IACfC,KAAK,EAAEf,OAAO,CAACe,KAAK;IACpBC,OAAO,EAAE,IAAI;IACbC,SAAS,EAAER,QAAQ;IACnBS,QAAQ,EAAEpB,IAAI,CAACqB,SAAS,CAACnB,OAAO,EAAE,UAAU,EAAE,IAAI,CAAC;IACnDoB,WAAW,EAAE,CAAC;IACdC,UAAU,EAAEvB,IAAI,CAACqB,SAAS,CAACnB,OAAO,EAAE,YAAY,EAAE,QAAQ;EAC9D,CAAC,CAAC;EACF;EACA;EACA;EACA;EACA,IAAIsB,MAAM,GAAGC,KAAK,CAAC9B,OAAO,CAACiB,GAAG,CAACY,MAAM,CAAC,GAChCZ,GAAG,CAACY,MAAM,GACVvC,OAAO,CAAC,SAAS,CAAC,CAACyC,QAAQ,CAACpB,iBAAiB,EAAE;IAC7CS,GAAG,EAAE;EACT,CAAC,CAAC;EACN;EACA,OAAOH,GAAG,CAACY,MAAM;EACjB;EACAA,MAAM,CAACG,OAAO,CAAC,UAAUC,KAAK,EAAE;IAC5B,IAAI,OAAOA,KAAK,CAAC9C,KAAK,KAAK,QAAQ,EAAE;MACjC8C,KAAK,CAAC9C,KAAK,GAAGsB,KAAK,CAACyB,WAAW,CAACD,KAAK,CAACb,GAAG,CAACe,KAAK,EAAEF,KAAK,CAACb,GAAG,CAACgB,GAAG,CAAC;IACnE;EACJ,CAAC,CAAC;EACF,IAAIN,KAAK,CAAC9B,OAAO,CAACiB,GAAG,CAACD,QAAQ,CAAC,EAAE;IAC7BA,QAAQ,GAAGC,GAAG,CAACD,QAAQ;IACvB,OAAOC,GAAG,CAACD,QAAQ;EACvB;EACA,IAAIC,GAAG,CAACG,GAAG,EAAE;IACT;IACA;IACAf,IAAI,CAACgC,kBAAkB,CAACpB,GAAG,EAAER,KAAK,CAAC;EACvC,CAAC,MACI;IACDQ,GAAG,CAACG,GAAG,GAAG;MACNe,KAAK,EAAE1B,KAAK,CAAC6B,QAAQ,CAAC,CAAC;MACvBF,GAAG,EAAE3B,KAAK,CAAC8B,OAAO,CAAC;IACvB,CAAC;EACL;EACAtB,GAAG,CAACG,GAAG,CAACX,KAAK,GAAGA,KAAK;EACrBQ,GAAG,CAACG,GAAG,CAACoB,MAAM,GAAG,CAAC;EAClB,IAAIC,IAAI;EACR,IAAIC,OAAO;EACX,IAAIzB,GAAG,CAAC0B,IAAI,KAAK,SAAS,EAAE;IACxBD,OAAO,GAAGzB,GAAG;IACb;IACA;IACA;IACA;IACAwB,IAAI,GAAG9C,CAAC,CAAC8C,IAAI,CAACxB,GAAG,EAAEV,OAAO,CAACqC,cAAc,IAAI,IAAI,CAAC;IAClDH,IAAI,CAACrB,GAAG,GAAG;MACPe,KAAK,EAAE1B,KAAK,CAAC6B,QAAQ,CAAC,CAAC;MACvBF,GAAG,EAAE3B,KAAK,CAAC8B,OAAO,CAAC,CAAC;MACpB9B,KAAK,EAAEA,KAAK;MACZ+B,MAAM,EAAE;IACZ,CAAC;EACL,CAAC,MACI,IAAIvB,GAAG,CAAC0B,IAAI,KAAK,MAAM,EAAE;IAC1BF,IAAI,GAAGxB,GAAG;IACVyB,OAAO,GAAGD,IAAI,CAACC,OAAO;EAC1B;EACA;EACA,IAAInC,OAAO,CAACsB,MAAM,EAAE;IAChBY,IAAI,CAACZ,MAAM,GAAGA,MAAM;EACxB;EACA;EACA;EACA;EACA;EACA;EACA,IAAIgB,cAAc,GAAGxC,IAAI,CAACyC,UAAU,CAAC;IACjCH,IAAI,EAAED,OAAO,CAACC,IAAI;IAClBvB,GAAG,EAAEsB,OAAO,CAACtB,GAAG;IAChB2B,IAAI,EAAE,EAAE;IACR/B,QAAQ,EAAEA;EACd,CAAC,EAAEP,KAAK,CAAC;EACTiC,OAAO,CAACtB,GAAG,CAACe,KAAK,GAAGU,cAAc,CAACV,KAAK;EACxCO,OAAO,CAACtB,GAAG,CAACgB,GAAG,GAAGS,cAAc,CAACT,GAAG;EACpC;EACA;EACAhC,UAAU,CAAC4C,MAAM,CAAChC,QAAQ,EAAE0B,OAAO,CAACK,IAAI,CAACE,MAAM,GAAGR,IAAI,CAACC,OAAO,GAAGD,IAAI,EAAEhC,KAAK,CAAC;EAC7E;EACA;EACA,OAAO,IAAIyC,UAAU,CAACzC,KAAK,EAAEoB,MAAM,CAAC,CAACsB,IAAI,CAACV,IAAI,CAAC;AACnD;AACAvD,OAAO,CAACE,KAAK,GAAGA,KAAK;AACrB,IAAI8D,UAAU,GAAG,SAASA,UAAUA,CAACzC,KAAK,EAAEoB,MAAM,EAAE;EAChDtC,QAAQ,CAAC6D,OAAO,CAACC,EAAE,CAAC,IAAI,YAAYH,UAAU,CAAC;EAC/C,IAAI,CAACzC,KAAK,GAAGA,KAAK;EAClB,IAAI,CAACoB,MAAM,GAAGA,MAAM;EACpB,IAAI,CAACyB,eAAe,GAAG,CAAC;EACxB,IAAI,CAACC,aAAa,GAAG1B,MAAM,CAACoB,MAAM;EAClC,IAAI,CAACT,MAAM,GAAG,CAAC;EACf,IAAI,CAACgB,IAAI,GAAG,IAAIC,GAAG,CAAC,CAAC;AACzB,CAAC;AACD,IAAIC,GAAG,GAAGR,UAAU,CAACS,SAAS;AAC9BD,GAAG,CAACP,IAAI,GAAG,UAAUS,IAAI,EAAE;EACvB,IAAI,IAAI,CAACJ,IAAI,CAACK,GAAG,CAACD,IAAI,CAAC,EAAE;IACrB,OAAO,IAAI,CAACJ,IAAI,CAACM,GAAG,CAACF,IAAI,CAAC;EAC9B;EACA,IAAI5D,OAAO,CAAC+D,KAAK,CAACH,IAAI,CAAC,EAAE;IACrB,IAAII,MAAM,GAAG,IAAIlC,KAAK,CAAC8B,IAAI,CAACX,MAAM,CAAC;IACnC,IAAI,CAACO,IAAI,CAACS,GAAG,CAACL,IAAI,EAAEI,MAAM,CAAC;IAC3BJ,IAAI,CAAC5B,OAAO,CAAC,UAAUkC,IAAI,EAAEC,CAAC,EAAE;MAC5BH,MAAM,CAACG,CAAC,CAAC,GAAG,IAAI,CAAChB,IAAI,CAACe,IAAI,CAAC;IAC/B,CAAC,EAAE,IAAI,CAAC;IACR,OAAOF,MAAM;EACjB;EACA,IAAI,CAACnE,QAAQ,CAACkE,KAAK,CAACH,IAAI,CAAC,EAAE;IACvB,OAAOA,IAAI;EACf;EACAvD,IAAI,CAACgC,kBAAkB,CAACuB,IAAI,EAAE,IAAI,CAACnD,KAAK,CAAC;EACzC,IAAI0C,IAAI,GAAGnE,MAAM,CAACoF,MAAM,CAACpF,MAAM,CAACqF,cAAc,CAACT,IAAI,CAAC,EAAE;IAClDU,QAAQ,EAAE;MACN;MACAnF,KAAK,EAAEyE,IAAI;MACXW,YAAY,EAAE,KAAK;MACnBC,UAAU,EAAE,KAAK;MACjBC,QAAQ,EAAE;IACd;EACJ,CAAC,CAAC;EACF,IAAI,CAACjB,IAAI,CAACS,GAAG,CAACL,IAAI,EAAET,IAAI,CAAC;EACzB,IAAI/B,GAAG,GAAGwC,IAAI,CAACxC,GAAG;EAClB,IAAIsD,SAAS,GAAG,IAAI,CAAClC,MAAM;EAC3B,IAAImC,SAAS,GAAGD,SAAS;EACzB,IAAIE,kBAAkB,GAAG,IAAI,CAACtB,eAAe;EAC7C,IAAIuB,gBAAgB,GAAG,IAAI,CAACtB,aAAa;EACzC,IAAInC,GAAG,EAAE;IACL;IACA;IACA;IACA;IACA;IACA,IAAIwC,IAAI,CAACjB,IAAI,KAAK,OAAO,IACrBiB,IAAI,CAACjB,IAAI,KAAK,MAAM,IACpBiB,IAAI,CAACjB,IAAI,KAAK,cAAc,IAC5BiB,IAAI,CAACjB,IAAI,KAAK,aAAa,IAC3B,IAAI,CAAClC,KAAK,CAACqE,0BAA0B,CAAC1D,GAAG,CAACe,KAAK,CAAC,EAAE;MAClDwC,SAAS,GAAG,IAAI,CAACnC,MAAM,GAAGpB,GAAG,CAACe,KAAK,CAAC4C,MAAM;IAC9C;IACA;IACA;IACA3D,GAAG,CAACX,KAAK,GAAG,IAAI,CAACA,KAAK;IACtBW,GAAG,CAACS,MAAM,GAAG,IAAI,CAACA,MAAM;IACxBT,GAAG,CAACoB,MAAM,GAAGmC,SAAS;IACtB;IACA;IACA;IACA,IAAI,CAACK,cAAc,CAAC5D,GAAG,CAAC;EAC5B;EACA,IAAI6D,IAAI,GAAGjG,MAAM,CAACiG,IAAI,CAACrB,IAAI,CAAC;EAC5B,IAAIsB,QAAQ,GAAGD,IAAI,CAAChC,MAAM;EAC1B,KAAK,IAAIkB,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGe,QAAQ,EAAE,EAAEf,CAAC,EAAE;IAC/B,IAAIgB,GAAG,GAAGF,IAAI,CAACd,CAAC,CAAC;IACjB,IAAIgB,GAAG,KAAK,KAAK,EAAE;MACfhC,IAAI,CAACgC,GAAG,CAAC,GAAGvB,IAAI,CAACuB,GAAG,CAAC;IACzB,CAAC,MACI,IAAIA,GAAG,KAAK,QAAQ,IAAIvB,IAAI,CAACjB,IAAI,KAAK,MAAM,EAAE;MAC/C;MACA;MACAQ,IAAI,CAACgC,GAAG,CAAC,GAAGvB,IAAI,CAACuB,GAAG,CAAC;IACzB,CAAC,MACI;MACDhC,IAAI,CAACgC,GAAG,CAAC,GAAG,IAAI,CAAChC,IAAI,CAACS,IAAI,CAACuB,GAAG,CAAC,CAAC;IACpC;EACJ;EACA,IAAI,CAAC3C,MAAM,GAAGkC,SAAS;EACvB,IAAI,CAACpB,eAAe,GAAGsB,kBAAkB;EACzC,IAAI,CAACrB,aAAa,GAAGsB,gBAAgB;EACrC,OAAO1B,IAAI;AACf,CAAC;AACD;AACA;AACA;AACA;AACA;AACAO,GAAG,CAACsB,cAAc,GAAG,UAAU5D,GAAG,EAAE;EAChC;EACA;EACA,OAAO,IAAI,CAACkC,eAAe,GAAG,CAAC,EAAE;IAC7B,IAAIrB,KAAK,GAAGb,GAAG,CAACS,MAAM,CAAC,IAAI,CAACyB,eAAe,CAAC;IAC5C,IAAIjD,IAAI,CAAC+E,UAAU,CAAChE,GAAG,CAACe,KAAK,EAAEF,KAAK,CAACb,GAAG,CAACe,KAAK,CAAC,GAAG,CAAC,EAAE;MACjD,EAAE,IAAI,CAACmB,eAAe;IAC1B,CAAC,MAEG;EACR;EACA;EACA;EACA,OAAO,IAAI,CAACC,aAAa,GAAGnC,GAAG,CAACS,MAAM,CAACoB,MAAM,EAAE;IAC3C,IAAIhB,KAAK,GAAGb,GAAG,CAACS,MAAM,CAAC,IAAI,CAAC0B,aAAa,CAAC;IAC1C,IAAIlD,IAAI,CAAC+E,UAAU,CAACnD,KAAK,CAACb,GAAG,CAACgB,GAAG,EAAEhB,GAAG,CAACgB,GAAG,CAAC,GAAG,CAAC,EAAE;MAC7C,EAAE,IAAI,CAACmB,aAAa;IACxB,CAAC,MAEG;EACR;EACA;EACA;EACA,OAAO,IAAI,CAACD,eAAe,GAAG,IAAI,CAACC,aAAa,EAAE;IAC9C,IAAItB,KAAK,GAAGb,GAAG,CAACS,MAAM,CAAC,IAAI,CAACyB,eAAe,CAAC;IAC5C,IAAIjD,IAAI,CAAC+E,UAAU,CAACnD,KAAK,CAACb,GAAG,CAACe,KAAK,EAAEf,GAAG,CAACe,KAAK,CAAC,GAAG,CAAC,EAAE;MACjD,EAAE,IAAI,CAACmB,eAAe;IAC1B,CAAC,MAEG;EACR;EACA;EACAlC,GAAG,CAACe,KAAK,CAACF,KAAK,GAAG,IAAI,CAACqB,eAAe;EACtC;EACA;EACA,OAAO,IAAI,CAACC,aAAa,GAAG,IAAI,CAACD,eAAe,EAAE;IAC9C,IAAIrB,KAAK,GAAGb,GAAG,CAACS,MAAM,CAAC,IAAI,CAAC0B,aAAa,GAAG,CAAC,CAAC;IAC9C,IAAIlD,IAAI,CAAC+E,UAAU,CAAChE,GAAG,CAACgB,GAAG,EAAEH,KAAK,CAACb,GAAG,CAACgB,GAAG,CAAC,GAAG,CAAC,EAAE;MAC7C,EAAE,IAAI,CAACmB,aAAa;IACxB,CAAC,MAEG;EACR;EACA;EACA;EACA;EACAnC,GAAG,CAACgB,GAAG,CAACH,KAAK,GAAG,IAAI,CAACsB,aAAa;AACtC,CAAC"},"metadata":{},"sourceType":"script"}